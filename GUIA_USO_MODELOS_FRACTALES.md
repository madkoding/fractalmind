# Gu√≠a de Uso: Sistema de Modelos Fractales

## üöÄ Inicio R√°pido

### 1. Iniciar el Backend

```bash
# Terminal 1: Iniciar SurrealDB
surreal start --log trace --user root --pass root file://fractalmind.db

# Terminal 2: Iniciar el servidor Rust
cd fractalmind
cargo run --release
```

El servidor estar√° disponible en `http://localhost:3000`

### 2. Iniciar el Frontend

```bash
# Terminal 3: Iniciar la UI
cd fractalmind/ui
npm install
npm run dev
```

La UI estar√° disponible en `http://localhost:5173`

## üìö Uso de la Interfaz

### Vista de Modelos

1. **Acceder al Gestor de Modelos**
   - Haz clic en el bot√≥n "Models" en la barra lateral
   - La interfaz cambiar√° de la vista de chat a la gesti√≥n de modelos

2. **Subir un Modelo GGUF**
   
   **Opci√≥n A: Drag & Drop**
   - Arrastra un archivo `.gguf` al √°rea de upload
   - El archivo se subir√° autom√°ticamente
   
   **Opci√≥n B: Selector de Archivos**
   - Haz clic en "Select File"
   - Selecciona tu archivo `.gguf`
   - El upload comenzar√° inmediatamente

3. **Ver Modelos Subidos**
   - Los modelos aparecen en una lista con:
     - Estado actual (uploading, converting, ready, failed)
     - Tama√±o del archivo
     - Fecha de creaci√≥n
     - Arquitectura (layers, embedding dimensions, vocab size)

4. **Convertir un Modelo a Fractal**
   - Una vez que el modelo est√© en estado "ready"
   - Haz clic en el bot√≥n de conversi√≥n (icono de refresh)
   - El estado cambiar√° a "converting"
   - La conversi√≥n se ejecuta en background

5. **Seleccionar Modelo Activo**
   - Haz clic en cualquier modelo de la lista
   - El modelo seleccionado tendr√° borde morado
   - Este ser√° el modelo usado cuando la estrategia sea "Fractal"

6. **Cambiar Estrategia de Inferencia**
   
   **Ollama (Direct)**:
   - Llamadas directas a la API de Ollama
   - M√°s r√°pido, menos control granular
   - No requiere conversi√≥n fractal
   
   **Fractal (Graph)**:
   - Navegaci√≥n jer√°rquica por grafo fractal
   - M√°s control, permite exploraci√≥n sem√°ntica
   - Requiere modelo convertido y seleccionado

7. **Eliminar un Modelo**
   - Haz clic en el icono de papelera (üóëÔ∏è)
   - Confirma la eliminaci√≥n
   - Se borrar√° el archivo GGUF y todos los datos relacionados

## üîß API REST

### Subir Modelo

```bash
curl -X POST http://localhost:3000/v1/models/upload \
  -F "file=@/path/to/model.gguf"
```

**Respuesta:**
```json
{
  "success": true,
  "model_id": "fractal_models:abc123",
  "message": "Model llama-2-7b.gguf uploaded successfully"
}
```

### Listar Modelos

```bash
curl http://localhost:3000/v1/models
```

**Respuesta:**
```json
{
  "models": [
    {
      "id": "fractal_models:abc123",
      "name": "llama-2-7b.gguf",
      "status": "ready",
      "architecture": {
        "model_type": "llama",
        "n_layers": 32,
        "embedding_dim": 4096,
        "vocab_size": 32000,
        "n_heads": 32,
        "ffn_dim": 11008
      },
      "file_size": 7000000000,
      "created_at": "2026-01-21T16:20:00Z"
    }
  ]
}
```

### Convertir Modelo

```bash
curl -X POST http://localhost:3000/v1/models/convert \
  -H "Content-Type: application/json" \
  -d '{"model_id": "fractal_models:abc123"}'
```

**Respuesta:**
```json
{
  "success": true,
  "message": "Model conversion started for fractal_models:abc123"
}
```

### Obtener Detalles de Modelo

```bash
curl http://localhost:3000/v1/models/fractal_models:abc123
```

### Eliminar Modelo

```bash
curl -X DELETE http://localhost:3000/v1/models/fractal_models:abc123
```

### Cambiar Estrategia

```bash
# Cambiar a Ollama
curl -X PATCH http://localhost:3000/v1/config/model-strategy \
  -H "Content-Type: application/json" \
  -d '{"strategy": "ollama"}'

# Cambiar a Fractal (requiere model_id)
curl -X PATCH http://localhost:3000/v1/config/model-strategy \
  -H "Content-Type: application/json" \
  -d '{"strategy": "fractal", "model_id": "fractal_models:abc123"}'
```

## üìñ Conceptos

### ¬øQu√© es un Modelo Fractal?

Un modelo fractal es una representaci√≥n jer√°rquica de un modelo de lenguaje que permite:

1. **Navegaci√≥n Sem√°ntica**: Explora el espacio de par√°metros del modelo siguiendo rutas de relevancia
2. **Estructura Auto-Similar**: Cada nivel del √°rbol contiene res√∫menes coherentes del nivel inferior
3. **B√∫squeda Eficiente**: Usa HNSW para encontrar r√°pidamente regiones relevantes
4. **S√≠ntesis Contextual**: Combina informaci√≥n de m√∫ltiples niveles para respuestas m√°s precisas

### Formato GGUF

GGUF (GPT-Generated Unified Format) es el formato usado por llama.cpp y Ollama:
- Almacena pesos del modelo cuantizados
- Incluye vocabulario y metadatos
- Optimizado para inferencia en CPU/GPU

### Proceso de Conversi√≥n

1. **Parseo**: Leer cabecera y metadatos del GGUF
2. **Extracci√≥n**: Obtener embeddings de capas del modelo
3. **Clustering**: Agrupar capas similares usando RAPTOR
4. **Jerarqu√≠a**: Crear √°rbol fractal con res√∫menes recursivos
5. **Indexaci√≥n**: Construir √≠ndice HNSW en SurrealDB

## üéØ Casos de Uso

### 1. Comparar Modelos

Sube m√∫ltiples variantes del mismo modelo (diferentes cuantizaciones) y compara:
- Tama√±o en disco
- Arquitectura
- Performance de conversi√≥n

### 2. Inferencia H√≠brida

- Usa **Ollama** para respuestas r√°pidas en conversaciones
- Cambia a **Fractal** cuando necesites exploraci√≥n profunda

### 3. An√°lisis de Arquitectura

Inspecciona la estructura interna de modelos:
- N√∫mero de capas
- Dimensiones de embeddings
- Tama√±o del vocabulario

## ‚ö†Ô∏è Limitaciones Actuales

1. **Conversi√≥n B√°sica**: La conversi√≥n fractal extrae metadatos pero a√∫n no genera la jerarqu√≠a RAPTOR completa
2. **Sin Progress Tracking**: No hay barra de progreso durante la conversi√≥n
3. **Storage Local**: Los archivos GGUF se almacenan en `/var/tmp/fractalmind_models`
4. **Sin Streaming**: La subida no soporta archivos parciales (usa el archivo completo)

## üîú Pr√≥ximas Mejoras

- [ ] Implementaci√≥n completa de RAPTOR para conversi√≥n
- [ ] Barra de progreso en tiempo real
- [ ] Soporte para m√∫ltiples formatos (safetensors, pytorch)
- [ ] Comparaci√≥n visual entre modelos
- [ ] Export/import de modelos convertidos

## üêõ Troubleshooting

### El modelo no se sube

- Verifica que sea un archivo `.gguf` v√°lido
- Revisa el tama√±o (archivos >50GB pueden fallar)
- Comprueba el espacio en disco de `/var/tmp`

### La conversi√≥n falla

- Mira los logs del backend: `cargo run` mostrar√° errores
- Verifica que SurrealDB est√© corriendo
- Comprueba que el archivo GGUF no est√© corrupto

### La estrategia Fractal no funciona

- Aseg√∫rate de tener un modelo seleccionado
- El modelo debe estar en estado "ready"
- La implementaci√≥n RAPTOR completa est√° pendiente (v0.2)

## üìû Soporte

Para reportar bugs o solicitar features:
- Revisa los logs: `cargo run` (backend) y consola del navegador (frontend)
- Abre un issue con detalles del modelo y error
- Incluye el output de `cargo --version` y `npm --version`

---

**Versi√≥n**: 0.1.0  
**Fecha**: 2026-01-21  
**Estado**: Frontend funcional, conversi√≥n b√°sica implementada
